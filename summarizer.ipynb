{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport tensorflow as tf\ntf.enable_eager_execution()\nimport time\nimport re\nimport string\nimport os\nprint(os.listdir(\"../input\"))\nimport matplotlib.pyplot as plt\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['database.sqlite', 'hashes.txt', 'Reviews.csv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "df = pd.read_csv('../input/Reviews.csv', delimiter = ',')\ndf.head()",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "   Id                        ...                                                                       Text\n0   1                        ...                          I have bought several of the Vitality canned d...\n1   2                        ...                          Product arrived labeled as Jumbo Salted Peanut...\n2   3                        ...                          This is a confection that has been around a fe...\n3   4                        ...                          If you are looking for the secret ingredient i...\n4   5                        ...                          Great taffy at a great price.  There was a wid...\n\n[5 rows x 10 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>ProfileName</th>\n      <th>HelpfulnessNumerator</th>\n      <th>HelpfulnessDenominator</th>\n      <th>Score</th>\n      <th>Time</th>\n      <th>Summary</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>delmartian</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1303862400</td>\n      <td>Good Quality Dog Food</td>\n      <td>I have bought several of the Vitality canned d...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>B00813GRG4</td>\n      <td>A1D87F6ZCVE5NK</td>\n      <td>dll pa</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1346976000</td>\n      <td>Not as Advertised</td>\n      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>B000LQOCH0</td>\n      <td>ABXLMWJIXXAIN</td>\n      <td>Natalia Corres \"Natalia Corres\"</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1219017600</td>\n      <td>\"Delight\" says it all</td>\n      <td>This is a confection that has been around a fe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>B000UA0QIQ</td>\n      <td>A395BORC6FGVXV</td>\n      <td>Karl</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1307923200</td>\n      <td>Cough Medicine</td>\n      <td>If you are looking for the secret ingredient i...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>B006K2ZZ7K</td>\n      <td>A1UQRSCLF8GW1T</td>\n      <td>Michael D. Bigham \"M. Wassir\"</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1350777600</td>\n      <td>Great taffy</td>\n      <td>Great taffy at a great price.  There was a wid...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ab605c145c12323f8923b73ebf3ec34aa284555a"
      },
      "cell_type": "code",
      "source": "def preprocess_sentence(w):\n    w = w.lower().strip()\n    \n    # creating a space between a word and the punctuation following it\n    # eg: \"he is a boy.\" => \"he is a boy .\" \n    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n    w = re.sub(r'[\" \"]+', \" \", w)\n    \n    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n    \n    w = w.rstrip().strip()\n    \n    # adding a start and an end token to the sentence\n    # so that the model know when to start and stop predicting.\n    w = '<start> ' + w + ' <end>'\n    return w\n\nclean_text = [preprocess_sentence(str(text)) for text in df['Text']]\nclean_summaries = [preprocess_sentence(str(text)) for text in df['Summary']]\n\n# 1. Remove the accents\n# 2. Clean the sentences\n# 3. Return word pairs in the format: [ENGLISH, SPANISH]\ndef create_dataset():    \n    word_pairs = [[text, summary]  for text, summary in zip(clean_text, clean_summaries)]\n    return word_pairs[:1000]\n\npairs = create_dataset()\npairs[:10]",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "[['<start> i have bought several of the vitality canned dog food products and have found them all to be of good quality . the product looks more like a stew than a processed meat and it smells better . my labrador is finicky and she appreciates this product better than most . <end>',\n  '<start> good quality dog food <end>'],\n ['<start> product arrived labeled as jumbo salted peanuts . . . the peanuts were actually small sized unsalted . not sure if this was an error or if the vendor intended to represent the product as jumbo . <end>',\n  '<start> not as advertised <end>'],\n ['<start> this is a confection that has been around a few centuries . it is a light , pillowy citrus gelatin with nuts in this case filberts . and it is cut into tiny squares and then liberally coated with powdered sugar . and it is a tiny mouthful of heaven . not too chewy , and very flavorful . i highly recommend this yummy treat . if you are familiar with the story of c . s . lewis the lion , the witch , and the wardrobe this is the treat that seduces edmund into selling out his brother and sisters to the witch . <end>',\n  '<start> delight says it all <end>'],\n ['<start> if you are looking for the secret ingredient in robitussin i believe i have found it . i got this in addition to the root beer extract i ordered which was good and made some cherry soda . the flavor is very medicinal . <end>',\n  '<start> cough medicine <end>'],\n ['<start> great taffy at a great price . there was a wide assortment of yummy taffy . delivery was very quick . if your a taffy lover , this is a deal . <end>',\n  '<start> great taffy <end>'],\n ['<start> i got a wild hair for taffy and ordered this five pound bag . the taffy was all very enjoyable with many flavors watermelon , root beer , melon , peppermint , grape , etc . my only complaint is there was a bit too much red black licorice flavored pieces just not my particular favorites . between me , my kids , and my husband , this lasted only two weeks ! i would recommend this brand of taffy it was a delightful treat . <end>',\n  '<start> nice taffy <end>'],\n ['<start> this saltwater taffy had great flavors and was very soft and chewy . each candy was individually wrapped well . none of the candies were stuck together , which did happen in the expensive version , fralinger s . would highly recommend this candy ! i served it at a beach themed party and everyone loved it ! <end>',\n  '<start> great ! just as good as the expensive brands ! <end>'],\n ['<start> this taffy is so good . it is very soft and chewy . the flavors are amazing . i would definitely recommend you buying it . very satisfying ! ! <end>',\n  '<start> wonderful , tasty taffy <end>'],\n ['<start> right now i m mostly just sprouting this so my cats can eat the grass . they love it . i rotate it around with wheatgrass and rye too <end>',\n  '<start> yay barley <end>'],\n ['<start> this is a very healthy dog food . good for their digestion . also good for small puppies . my dog eats her required amount at every feeding . <end>',\n  '<start> healthy dog food <end>']]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a6f9658291a76b5b509b07dc5779e2684297adae"
      },
      "cell_type": "code",
      "source": "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n# (e.g., 5 -> \"dad\") for each language,\nclass LanguageIndex():\n  def __init__(self, lang):\n    self.lang = lang\n    self.word2idx = {}\n    self.idx2word = {}\n    self.vocab = set()\n    \n    self.create_index()\n    \n  def create_index(self):\n    for phrase in self.lang:\n      self.vocab.update(phrase.split(' '))\n    \n    self.vocab = sorted(self.vocab)\n    \n    self.word2idx['<pad>'] = 0\n    for index, word in enumerate(self.vocab):\n      self.word2idx[word] = index + 1\n    \n    for word, index in self.word2idx.items():\n      self.idx2word[index] = word",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "19e261c32c3b175ece3220595b3e89b0fd6d17ad"
      },
      "cell_type": "code",
      "source": "def max_length(tensor):\n    return max(len(t) for t in tensor)\n\n\ndef load_dataset():\n    # creating cleaned input, output pairs\n    pairs = create_dataset()\n\n    # index language using the class defined above    \n    inp_lang = LanguageIndex(text for text, summary in pairs)\n    targ_lang = LanguageIndex(summary for text, summary in pairs)\n    \n    # Vectorize the input and target languages\n    \n    # Spanish sentences\n    input_tensor = [[inp_lang.word2idx[s] for s in text.split(' ')] for text, summary in pairs]\n    \n    # English sentences\n    target_tensor = [[targ_lang.word2idx[s] for s in summary.split(' ')] for text, summary in pairs]\n    \n    # Calculate max_length of input and output tensor\n    # Here, we'll set those to the longest sentence in the dataset\n    max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)\n    \n    # Padding the input and output tensor to the maximum length\n    input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, \n                                                                 maxlen=max_length_inp,\n                                                                 padding='post')\n    \n    target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, \n                                                                  maxlen=max_length_tar, \n                                                                  padding='post')\n    \n    return input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_tar",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "abe9163bca1f0e7d285383277822c2962fc6fbab"
      },
      "cell_type": "code",
      "source": "input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_targ = load_dataset()",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2ffa42ff10115152259e1061c0ad7705aa2ab5a2"
      },
      "cell_type": "code",
      "source": "input_tensor",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "array([[   5, 2522, 2354, ...,    0,    0,    0],\n       [   5, 3947,  277, ...,    0,    0,    0],\n       [   5, 5227, 2663, ...,    0,    0,    0],\n       ...,\n       [   5, 5227, 4399, ...,    0,    0,    0],\n       [   5, 3410, 2478, ...,    0,    0,    0],\n       [   5, 2522, 2354, ...,    0,    0,    0]], dtype=int32)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "80bab89207dc0cfca3001219dd7dbf4b6652c220"
      },
      "cell_type": "code",
      "source": "input_tensor.shape",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "(1000, 1123)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6f4d8bee8b19c4c11b2e4febd314557d7d47d126"
      },
      "cell_type": "code",
      "source": "max_length_inp",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "1123"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "37db315390c7812a532c9322b8397aa56d324b9b"
      },
      "cell_type": "code",
      "source": "max_length_targ",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "56"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6abde09b37ae8fd269c1af45e753ae1ef557e904"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\ninput_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n\n# Show length\nlen(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "(800, 800, 200, 200)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7b26c1a52b8174c3adb777a75e3096796a338cd8"
      },
      "cell_type": "code",
      "source": "config = tf.ConfigProto(allow_soft_placement=True)\nconfig.gpu_options.allocator_type = 'BFC'\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.80\n\nBUFFER_SIZE = len(input_tensor_train)\nBATCH_SIZE = 16\nN_BATCH = BUFFER_SIZE//BATCH_SIZE\nembedding_dim = 256\nunits = 256\nvocab_inp_size = len(inp_lang.word2idx)\nvocab_tar_size = len(targ_lang.word2idx)\n\ndataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\ndataset = dataset.batch(BATCH_SIZE, drop_remainder=True)",
      "execution_count": 34,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a03b4a910f160e9b6430cdca2372488962028ce"
      },
      "cell_type": "code",
      "source": "def gru(units):\n  # If you have a GPU, we recommend using CuDNNGRU(provides a 3x speedup than GRU)\n  # the code automatically does that.\n  if tf.test.is_gpu_available():\n    return tf.keras.layers.CuDNNGRU(units, \n                                    return_sequences=True, \n                                    return_state=True, \n                                    recurrent_initializer='glorot_uniform')\n  else:\n    return tf.keras.layers.GRU(units, \n                               return_sequences=True, \n                               return_state=True, \n                               recurrent_activation='sigmoid', \n                               recurrent_initializer='glorot_uniform')",
      "execution_count": 35,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c65946e1e54af5afa1fcdfd92a088e16bcf64686"
      },
      "cell_type": "code",
      "source": "\nclass Encoder(tf.keras.Model):\n    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n        super(Encoder, self).__init__()\n        self.batch_sz = batch_sz\n        self.enc_units = enc_units\n        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n        self.gru = gru(self.enc_units)\n        \n    def call(self, x, hidden):\n        x = self.embedding(x)\n        output, state = self.gru(x, initial_state = hidden)        \n        return output, state\n    \n    def initialize_hidden_state(self):\n        return tf.zeros((self.batch_sz, self.enc_units))",
      "execution_count": 36,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3bbd229d7c1263172d937a7d7ce13c3c2aff5f79"
      },
      "cell_type": "code",
      "source": "class Decoder(tf.keras.Model):\n    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n        super(Decoder, self).__init__()\n        self.batch_sz = batch_sz\n        self.dec_units = dec_units\n        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n        self.gru = gru(self.dec_units)\n        self.fc = tf.keras.layers.Dense(vocab_size)\n        \n        # used for attention\n        self.W1 = tf.keras.layers.Dense(self.dec_units)\n        self.W2 = tf.keras.layers.Dense(self.dec_units)\n        self.V = tf.keras.layers.Dense(1)\n        \n    def call(self, x, hidden, enc_output):\n        # enc_output shape == (batch_size, max_length, hidden_size)\n        \n        # hidden shape == (batch_size, hidden size)\n        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n        # we are doing this to perform addition to calculate the score\n        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n        \n        # score shape == (batch_size, max_length, hidden_size)\n        score = tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis))\n        \n        # attention_weights shape == (batch_size, max_length, 1)\n        # we get 1 at the last axis because we are applying score to self.V\n        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n        \n        # context_vector shape after sum == (batch_size, hidden_size)\n        context_vector = attention_weights * enc_output\n        context_vector = tf.reduce_sum(context_vector, axis=1)\n        \n        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n        x = self.embedding(x)\n        \n        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n        \n        # passing the concatenated vector to the GRU\n        output, state = self.gru(x)\n        \n        # output shape == (batch_size * 1, hidden_size)\n        output = tf.reshape(output, (-1, output.shape[2]))\n        \n        # output shape == (batch_size * 1, vocab)\n        x = self.fc(output)\n        \n        return x, state, attention_weights\n        \n    def initialize_hidden_state(self):\n        return tf.zeros((self.batch_sz, self.dec_units))",
      "execution_count": 37,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a0a33b09fdcd431593ab1008336e8dbaccd37921"
      },
      "cell_type": "code",
      "source": "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\ndecoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)",
      "execution_count": 38,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d645de5a3bdbe85f20b604a1afca57b3e5bbda7f"
      },
      "cell_type": "code",
      "source": "optimizer = tf.train.AdamOptimizer()\n\n\ndef loss_function(real, pred):\n  mask = 1 - np.equal(real, 0)\n  loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n  return tf.reduce_mean(loss_)",
      "execution_count": 39,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "80c2a13ab9992ba80435a8235083615e5c156b3e"
      },
      "cell_type": "code",
      "source": "import os\ncheckpoint_dir = './training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(optimizer=optimizer,\n                                 encoder=encoder,\n                                 decoder=decoder)",
      "execution_count": 40,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0608571b4f8d5cd156523986cc06fcdb6f22b448"
      },
      "cell_type": "code",
      "source": "EPOCHS = 10\n\nfor epoch in range(EPOCHS):\n    start = time.time()\n    \n    hidden = encoder.initialize_hidden_state()\n    total_loss = 0\n    \n    for (batch, (inp, targ)) in enumerate(dataset):\n        loss = 0\n        \n        with tf.GradientTape() as tape:\n            enc_output, enc_hidden = encoder(inp, hidden)\n            \n            dec_hidden = enc_hidden\n            \n            dec_input = tf.expand_dims([targ_lang.word2idx['<start>']] * BATCH_SIZE, 1)       \n            \n            # Teacher forcing - feeding the target as the next input\n            for t in range(1, targ.shape[1]):\n                # passing enc_output to the decoder\n                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n                \n                loss += loss_function(targ[:, t], predictions)\n                \n                # using teacher forcing\n                dec_input = tf.expand_dims(targ[:, t], 1)\n        \n        batch_loss = (loss / int(targ.shape[1]))\n        \n        total_loss += batch_loss\n        \n        variables = encoder.variables + decoder.variables\n        \n        gradients = tape.gradient(loss, variables)\n        \n        optimizer.apply_gradients(zip(gradients, variables))\n        \n        if batch % 100 == 0:\n            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n                                                         batch,\n                                                         batch_loss.numpy()))\n    # saving (checkpoint) the model every 2 epochs\n    if (epoch + 1) % 2 == 0:\n      checkpoint.save(file_prefix = checkpoint_prefix)\n    \n    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n                                        total_loss / N_BATCH))\n    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Epoch 1 Batch 0 Loss 0.3672\nEpoch 1 Loss 0.5307\nTime taken for 1 epoch 72.4614417552948 sec\n\nEpoch 2 Batch 0 Loss 0.4745\nEpoch 2 Loss 0.5057\nTime taken for 1 epoch 72.61180472373962 sec\n\nEpoch 3 Batch 0 Loss 0.4202\nEpoch 3 Loss 0.4869\nTime taken for 1 epoch 72.01322841644287 sec\n\nEpoch 4 Batch 0 Loss 0.4487\nEpoch 4 Loss 0.4727\nTime taken for 1 epoch 72.1374442577362 sec\n\nEpoch 5 Batch 0 Loss 0.2884\nEpoch 5 Loss 0.4598\nTime taken for 1 epoch 71.90825891494751 sec\n\nEpoch 6 Batch 0 Loss 0.4335\nEpoch 6 Loss 0.4432\nTime taken for 1 epoch 72.37527394294739 sec\n\nEpoch 7 Batch 0 Loss 0.6162\nEpoch 7 Loss 0.4292\nTime taken for 1 epoch 72.12824058532715 sec\n\nEpoch 8 Batch 0 Loss 0.5227\nEpoch 8 Loss 0.4122\nTime taken for 1 epoch 72.04292917251587 sec\n\nEpoch 9 Batch 0 Loss 0.3677\nEpoch 9 Loss 0.3947\nTime taken for 1 epoch 71.8166389465332 sec\n\nEpoch 10 Batch 0 Loss 0.3225\nEpoch 10 Loss 0.3772\nTime taken for 1 epoch 72.27637434005737 sec\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "23c64cf33687af7fd3b71c1263f0161efe7d1012"
      },
      "cell_type": "code",
      "source": "def evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n    attention_plot = np.zeros((max_length_targ, max_length_inp))\n    \n    sentence = preprocess_sentence(sentence)\n\n    inputs = [inp_lang.word2idx[i] for i in sentence.split(' ')]\n    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n    inputs = tf.convert_to_tensor(inputs)\n    \n    result = ''\n\n    hidden = [tf.zeros((1, units))]\n    enc_out, enc_hidden = encoder(inputs, hidden)\n\n    dec_hidden = enc_hidden\n    dec_input = tf.expand_dims([targ_lang.word2idx['<start>']], 0)\n\n    for t in range(max_length_targ):\n        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n        \n        # storing the attention weigths to plot later on\n        attention_weights = tf.reshape(attention_weights, (-1, ))\n        attention_plot[t] = attention_weights.numpy()\n\n        predicted_id = tf.multinomial(predictions, num_samples=1)[0][0].numpy()\n\n        result += targ_lang.idx2word[predicted_id] + ' '\n\n        if targ_lang.idx2word[predicted_id] == '<end>':\n            return result, sentence, attention_plot\n        \n        # the predicted ID is fed back into the model\n        dec_input = tf.expand_dims([predicted_id], 0)\n\n    return result, sentence, attention_plot",
      "execution_count": 51,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7b56fcff94e5165c10493742f206b5bdb912c0af"
      },
      "cell_type": "code",
      "source": "# function for plotting the attention weights\ndef plot_attention(attention, sentence, predicted_sentence):\n    fig = plt.figure(figsize=(10,10))\n    ax = fig.add_subplot(1, 1, 1)\n    ax.matshow(attention, cmap='viridis')\n    \n    fontdict = {'fontsize': 14}\n    \n    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n\n    plt.show()",
      "execution_count": 52,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d1f91425c6ddd6179f54eb7cf981723b2aa42a82"
      },
      "cell_type": "code",
      "source": "def summarize(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)\n        \n    print('Input: {}'.format(sentence))\n    print(': {}'.format(result))\n    \n    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n    plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n    return result",
      "execution_count": 53,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "430baf4b8899d5e9def9b5a52ee296f81f8ef782"
      },
      "cell_type": "code",
      "source": "summarize('this is a very healthy dog food . good for their digestion . also good for small puppies . my dog eats her required amount at every feeding',\n          encoder, \n          decoder, \n          inp_lang, \n          targ_lang, \n          max_length_inp, \n          max_length_targ)\n",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Input: <start> this is a very healthy dog food . good for their digestion . also good for small puppies . my dog eats her required amount at every feeding <end>\n: love too <end> \n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 720x720 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 56,
          "data": {
            "text/plain": "'love too <end> '"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a0132ad019d22efa309ff50acf5630a27ab75d72"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}